{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "4qKhx3bD3eqf",
    "outputId": "b916d781-1aad-412c-9920-bce7dc311d4e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "g9E-w4Mkopd7",
    "outputId": "39db449e-5b5e-4bbc-b933-ff04f8804065"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "data_path_folder = \"./drive/My Drive/Colab Notebooks/face_anti_spoofing/\"\n",
    "TRAIN_DIR = data_path_folder + 'train/'\n",
    "TEST_DIR = data_path_folder + \"test/\"\n",
    "\n",
    "n_real = len(os.listdir(TRAIN_DIR + \"/real\"))\n",
    "n_spoof = len(os.listdir(TRAIN_DIR + \"/spoof\"))\n",
    "n_real, n_spoof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7tzYm6ZE7T4"
   },
   "source": [
    "# **Remove invalid files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "2dAg2A2UFSlS",
    "outputId": "990e3bb5-b141-4322-cbcd-dd8d06ef5fc4"
   },
   "outputs": [],
   "source": [
    "def remove_img(directory: str):\n",
    "    counter = 0\n",
    "    for img_name in os.listdir(directory):\n",
    "        if img_name.find('.') == 0:\n",
    "            counter += 1\n",
    "            os.remove(directory + img_name)\n",
    "    print(f'removed {counter} files')\n",
    "\n",
    "remove_img(TRAIN_DIR + \"real/\")\n",
    "remove_img(TRAIN_DIR + \"spoof/\")\n",
    "# remove_img(TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVOluk8hFIds"
   },
   "source": [
    "# **Start**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dGli_Ba2mdN"
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmnet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "tcHL7rqg2nD2",
    "outputId": "b464d468-450a-4c8d-9bb1-0d3e5867c91f"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "val_share = 0.1\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=val_share,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "USsIgh14hhDo",
    "outputId": "87aac8e0-47b4-4f83-f553-edefe6ac57b2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "train_sample, y_train = next(train_generator)\n",
    "val_sample, y_val = next(val_generator)\n",
    "test_sample, y_test = next(test_generator)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "\n",
    "axes[0].imshow(train_sample[0])\n",
    "axes[0].set_title('Train sample')\n",
    "\n",
    "axes[1].imshow(val_sample[0])\n",
    "axes[1].set_title('Val sample')\n",
    "\n",
    "axes[2].imshow(test_sample[0])\n",
    "axes[2].set_title('Test sample')\n",
    "\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDy1oEumZiQb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras import utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow_addons.callbacks import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3l3NkbINb77"
   },
   "source": [
    "# **MobileNetV2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "qbJR7iKvNeqL",
    "outputId": "0a7465b5-eb42-438c-e4b9-7f2d56983192"
   },
   "outputs": [],
   "source": [
    "pretrain_MobileNetV2 = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(INPUT_SIZE, INPUT_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "\n",
    "\n",
    "# Add fully connected layer for classification\n",
    "def add_fc_func_model(func_model):\n",
    "    x = func_model.output\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=func_model.input, outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h-lL2Za7URvz",
    "outputId": "edf231eb-6341-4505-8bb9-76d2d1ba7d03"
   },
   "outputs": [],
   "source": [
    "model = add_fc_func_model(pretrain_MobileNetV2)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "class_weight = {0: (n_real + n_spoof) / n_real / 2, 1: (n_real + n_spoof) / n_spoof / 2}\n",
    "\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "wyvllnTkIMev",
    "outputId": "fe377854-8c22-4fd6-e89d-3bbf370e9434"
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=(1 - val_share) * (n_real + n_spoof) // BATCH_SIZE,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_share * (n_real + n_spoof) // BATCH_SIZE,\n",
    "        verbose=1,\n",
    "        callbacks=[    \n",
    "            ModelCheckpoint(\n",
    "                data_path_folder + 'checkpoints/MobileNetV2' + 'weights.{epoch:02d}-{loss:.2f}.h5',\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                save_best_only=True, \n",
    "                save_weights_only=False\n",
    "            ),\n",
    "        ],\n",
    "        class_weight=class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-U6XDpheCch"
   },
   "source": [
    "# **Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "BBnSDzCKJmUa",
    "outputId": "e1a08265-0f9a-4281-8079-fcd1ecf159c2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# model = load_model(data_path_folder + r\"checkpointsMobileNetV2weights.01-0.21.h5\")\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "with tf.device('/GPU:0'):    \n",
    "    predict = model.predict_generator(test_generator,steps = nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MZGdD8RtLGU5",
    "outputId": "ac20a9af-7bb3-496c-b308-b4d4f4ca65a1"
   },
   "outputs": [],
   "source": [
    "len(predict), len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to .txt and .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQltxF8xJl_s"
   },
   "outputs": [],
   "source": [
    "with open(data_path_folder + 'predictions.txt', 'w', encoding='utf-8') as f:\n",
    "    for file_name, prediction in zip(filenames, predict):\n",
    "        f.write(file_name + ',' + '{0:.16f}'.format(1 - prediction[0]) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdbjCu881kso"
   },
   "outputs": [],
   "source": [
    "with open(data_path_folder + 'predictions.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "new_lines = list(map(lambda line: line.split('/')[1], lines))\n",
    "\n",
    "with open(data_path_folder + 'predictions_edited.txt', 'w') as f:\n",
    "    f.write(''.join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "8TM1x1zA7uhD",
    "outputId": "bb87e70e-bdc8-4581-fa9e-494ca9e03325"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(data_path_folder + 'predictions_edited.txt', 'r') as infile, open(data_path_folder + 'predictions_table.csv', 'w') as outfile:\n",
    "     stripped = (line.strip() for line in infile)\n",
    "     lines = (line.split(\",\") for line in stripped if line)\n",
    "     print(list(lines))\n",
    "     writer = csv.writer(outfile, quoting=csv.QUOTE_NONNUMERIC)\n",
    "     writer.writerows(lines)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "w7tzYm6ZE7T4",
    "5TPbkrkmf7Qu",
    "x3l3NkbINb77",
    "m_ePCbaJg9u4",
    "XpYjlB7uLn1G"
   ],
   "name": "face_antispoofing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
